{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree 만들기\n",
    "\n",
    "- 어떤 질문이 가장 많은 해답을 줄 것인가?\n",
    "- 결국 어떤 질문은 답의 모호성을 줄여줄 것인가?\n",
    "- 문제를 통해서 splitting poing을 설정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "- Entropy는 목적 달성을 위한 경우의 수를 정량적으로 표현하는 수치임. 엔트로피가 작으면 경우의 수가 적음 (얻을 수 있는 정보가 명확하다)\n",
    "- Higher Entropy -> Higher uncertainty\n",
    "- Lower Entropy -> Lower uncertainty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growing a Decision Tree\n",
    "\n",
    "- Decision Tree를 성장(만드는)시키는 알고리즘이 필요함\n",
    "- 어떻게 하면 가장 잘 분기(branch)를 만들 수 있는가?\n",
    "- Data의 attribute를 기준으로 분기를 생성\n",
    "- 어떤 attribute를 기준으로 하면 가장 entropy가 작은가?\n",
    "- 하나를 자른 후에 그 다음은 어떻게 할 것인가?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree는 재귀적으로 생김\n",
    "- 대상 라벨에 대해 어떤 Attribute가 더 확실한 정보를 제공하고 있는가? 로 branch attribute를 선택함\n",
    "- 확실한 정보의 선택 기준은 알고리즘별로 차이가 있음\n",
    "- Tree 생성 후 pruning을 통해 Tree generalization 시행\n",
    "- 일반적으로 효율을 위해 Binary Tree를 사용함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree의 특징\n",
    "\n",
    "- 비교적 간단하고, 직관적으로 결과를 표현함 (설명하기도 좋음)\n",
    "- 훈련시간이 길고, 메모리 공간을 많이 사용함\n",
    "- Top-down, Recursive, Divide and Conquer 기법\n",
    "- Greedy 알고리즘 -> 부분 최적화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree의 장점\n",
    "\n",
    "- 트리의 상단 부분 attribute들이 가장 중요한 예측 변수일 가능성이 높음\n",
    "- Attribute의 scaling이 필요없음\n",
    "- 관측치의 절대값이 아닌 순서가 중요함 -> Outlier에 이점\n",
    "- 자동적 변수 부분 선택 (필요 없는 변수는 빨리 떨굼)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritms of Decision Tree\n",
    "\n",
    "- 크게 두 가지 형태의 decision tree 알고리즘이 존재함\n",
    "- 알고리즘 별 attribute branch 방법이 다름\n",
    "- ID3 -> C4.5(Ross Quinlan), CART\n",
    "- 연속형 변수를 위한 regression tree도 존재함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
