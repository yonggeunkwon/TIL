{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "datasets = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = datasets['data']\n",
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = datasets['target']\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data.reshape([-1, 1])\n",
    "y_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_data)\n",
    "y_data = enc.transform(y_data).toarray()\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min Max Scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_data_minmax = min_max_scaler.fit_transform(x_data)\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [1.        , 0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [1.        , 0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn을 사용하지 않는 경우에는 상수항을 따로 넣어줘야 함\n",
    "x_0 = np.ones(x_data_minmax.shape[0])\n",
    "x_data_minmax = np.column_stack((x_0, x_data_minmax))\n",
    "\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62499483, 0.53538091, 0.64729592, 0.10800148, 0.69535364],\n",
       "       [0.35656169, 0.66357964, 0.7353655 , 0.83634461, 0.30425367],\n",
       "       [0.32252844, 0.26357368, 0.49549324, 0.54259619, 0.17019918]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight matrix 생성\n",
    "weights = np.random.uniform(size=(3, 5))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    e = np.exp(z)\n",
    "    p = e / np.sum(np.exp(z), axis=1).reshape([-1, 1])\n",
    "    return p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18482352, 1.03300583, 0.73466146],\n",
       "       [1.02022682, 0.84293915, 0.61679072],\n",
       "       [1.04259422, 0.85317874, 0.6342423 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z = x와 theta_j의 linear combination임\n",
    "z = x_data_minmax.dot(weights.T)\n",
    "z[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40053355, 0.34411636, 0.25535009],\n",
       "       [0.39911245, 0.33427217, 0.26661538],\n",
       "       [0.40125391, 0.3320146 , 0.26673149],\n",
       "       [0.39587469, 0.33333273, 0.27079258],\n",
       "       [0.40039327, 0.34403316, 0.25557356]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각각의 class가 나올 확률을 instance별로 찍어줌\n",
    "softmax(z[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z[:5]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_function(y, x, weights):\n",
    "    z = x_data_minmax.dot(weights.T)\n",
    "    result = np.sum(\n",
    "        np.sum(\n",
    "        (y * np.log(softmax(z))), axis=1). reshape(([-1, 1]))\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91495774, -0.        , -0.        ],\n",
       "       [-0.91851208, -0.        , -0.        ],\n",
       "       [-0.91316086, -0.        , -0.        ],\n",
       "       [-0.92665756, -0.        , -0.        ],\n",
       "       [-0.91530803, -0.        , -0.        ],\n",
       "       [-0.90817349, -0.        , -0.        ],\n",
       "       [-0.90790858, -0.        , -0.        ],\n",
       "       [-0.92217797, -0.        , -0.        ],\n",
       "       [-0.9234123 , -0.        , -0.        ],\n",
       "       [-0.93552533, -0.        , -0.        ],\n",
       "       [-0.91852703, -0.        , -0.        ],\n",
       "       [-0.92983037, -0.        , -0.        ],\n",
       "       [-0.93068532, -0.        , -0.        ],\n",
       "       [-0.91702395, -0.        , -0.        ],\n",
       "       [-0.89713844, -0.        , -0.        ],\n",
       "       [-0.8936312 , -0.        , -0.        ],\n",
       "       [-0.88371713, -0.        , -0.        ],\n",
       "       [-0.90380684, -0.        , -0.        ],\n",
       "       [-0.91788007, -0.        , -0.        ],\n",
       "       [-0.90896683, -0.        , -0.        ],\n",
       "       [-0.93179001, -0.        , -0.        ],\n",
       "       [-0.8981826 , -0.        , -0.        ],\n",
       "       [-0.89406555, -0.        , -0.        ],\n",
       "       [-0.90054429, -0.        , -0.        ],\n",
       "       [-0.94845267, -0.        , -0.        ],\n",
       "       [-0.92994621, -0.        , -0.        ],\n",
       "       [-0.90590791, -0.        , -0.        ],\n",
       "       [-0.92041304, -0.        , -0.        ],\n",
       "       [-0.91460771, -0.        , -0.        ],\n",
       "       [-0.93147839, -0.        , -0.        ],\n",
       "       [-0.93111382, -0.        , -0.        ],\n",
       "       [-0.89716265, -0.        , -0.        ],\n",
       "       [-0.9299015 , -0.        , -0.        ],\n",
       "       [-0.91064079, -0.        , -0.        ],\n",
       "       [-0.92416996, -0.        , -0.        ],\n",
       "       [-0.90468643, -0.        , -0.        ],\n",
       "       [-0.90615867, -0.        , -0.        ],\n",
       "       [-0.92727902, -0.        , -0.        ],\n",
       "       [-0.91680812, -0.        , -0.        ],\n",
       "       [-0.92145493, -0.        , -0.        ],\n",
       "       [-0.89843667, -0.        , -0.        ],\n",
       "       [-0.90864577, -0.        , -0.        ],\n",
       "       [-0.91573999, -0.        , -0.        ],\n",
       "       [-0.8835094 , -0.        , -0.        ],\n",
       "       [-0.92249276, -0.        , -0.        ],\n",
       "       [-0.90809215, -0.        , -0.        ],\n",
       "       [-0.926318  , -0.        , -0.        ],\n",
       "       [-0.92007452, -0.        , -0.        ],\n",
       "       [-0.9191456 , -0.        , -0.        ],\n",
       "       [-0.9164367 , -0.        , -0.        ],\n",
       "       [-0.        , -0.86757756, -0.        ],\n",
       "       [-0.        , -0.90606089, -0.        ],\n",
       "       [-0.        , -0.86829372, -0.        ],\n",
       "       [-0.        , -0.99394587, -0.        ],\n",
       "       [-0.        , -0.91073322, -0.        ],\n",
       "       [-0.        , -0.93758245, -0.        ],\n",
       "       [-0.        , -0.8997478 , -0.        ],\n",
       "       [-0.        , -1.04259706, -0.        ],\n",
       "       [-0.        , -0.89358455, -0.        ],\n",
       "       [-0.        , -1.00175805, -0.        ],\n",
       "       [-0.        , -1.04232876, -0.        ],\n",
       "       [-0.        , -0.94982791, -0.        ],\n",
       "       [-0.        , -0.96299754, -0.        ],\n",
       "       [-0.        , -0.91167248, -0.        ],\n",
       "       [-0.        , -0.99101368, -0.        ],\n",
       "       [-0.        , -0.89915785, -0.        ],\n",
       "       [-0.        , -0.94381743, -0.        ],\n",
       "       [-0.        , -0.94627255, -0.        ],\n",
       "       [-0.        , -0.94992491, -0.        ],\n",
       "       [-0.        , -0.97838178, -0.        ],\n",
       "       [-0.        , -0.9225926 , -0.        ],\n",
       "       [-0.        , -0.95110251, -0.        ],\n",
       "       [-0.        , -0.91185792, -0.        ],\n",
       "       [-0.        , -0.90582146, -0.        ],\n",
       "       [-0.        , -0.91835316, -0.        ],\n",
       "       [-0.        , -0.90641738, -0.        ],\n",
       "       [-0.        , -0.88315595, -0.        ],\n",
       "       [-0.        , -0.88329803, -0.        ],\n",
       "       [-0.        , -0.9319796 , -0.        ],\n",
       "       [-0.        , -0.98933185, -0.        ],\n",
       "       [-0.        , -0.99225281, -0.        ],\n",
       "       [-0.        , -0.9933807 , -0.        ],\n",
       "       [-0.        , -0.9675918 , -0.        ],\n",
       "       [-0.        , -0.9094818 , -0.        ],\n",
       "       [-0.        , -0.95165957, -0.        ],\n",
       "       [-0.        , -0.91902067, -0.        ],\n",
       "       [-0.        , -0.88695554, -0.        ],\n",
       "       [-0.        , -0.93834523, -0.        ],\n",
       "       [-0.        , -0.95741748, -0.        ],\n",
       "       [-0.        , -0.98625687, -0.        ],\n",
       "       [-0.        , -0.95412342, -0.        ],\n",
       "       [-0.        , -0.91379827, -0.        ],\n",
       "       [-0.        , -0.96545883, -0.        ],\n",
       "       [-0.        , -1.04234923, -0.        ],\n",
       "       [-0.        , -0.96278808, -0.        ],\n",
       "       [-0.        , -0.94273249, -0.        ],\n",
       "       [-0.        , -0.95132296, -0.        ],\n",
       "       [-0.        , -0.92601351, -0.        ],\n",
       "       [-0.        , -1.05351399, -0.        ],\n",
       "       [-0.        , -0.96093865, -0.        ],\n",
       "       [-0.        , -0.        , -1.64031831],\n",
       "       [-0.        , -0.        , -1.50722767],\n",
       "       [-0.        , -0.        , -1.63901973],\n",
       "       [-0.        , -0.        , -1.54259464],\n",
       "       [-0.        , -0.        , -1.60485067],\n",
       "       [-0.        , -0.        , -1.67419297],\n",
       "       [-0.        , -0.        , -1.41488349],\n",
       "       [-0.        , -0.        , -1.61454676],\n",
       "       [-0.        , -0.        , -1.54506115],\n",
       "       [-0.        , -0.        , -1.72884774],\n",
       "       [-0.        , -0.        , -1.60193668],\n",
       "       [-0.        , -0.        , -1.54961876],\n",
       "       [-0.        , -0.        , -1.61894618],\n",
       "       [-0.        , -0.        , -1.4988612 ],\n",
       "       [-0.        , -0.        , -1.56777518],\n",
       "       [-0.        , -0.        , -1.625344  ],\n",
       "       [-0.        , -0.        , -1.56464632],\n",
       "       [-0.        , -0.        , -1.74715263],\n",
       "       [-0.        , -0.        , -1.67432779],\n",
       "       [-0.        , -0.        , -1.44901395],\n",
       "       [-0.        , -0.        , -1.65988242],\n",
       "       [-0.        , -0.        , -1.51159384],\n",
       "       [-0.        , -0.        , -1.65774029],\n",
       "       [-0.        , -0.        , -1.53487247],\n",
       "       [-0.        , -0.        , -1.62985706],\n",
       "       [-0.        , -0.        , -1.62819326],\n",
       "       [-0.        , -0.        , -1.53482608],\n",
       "       [-0.        , -0.        , -1.53946639],\n",
       "       [-0.        , -0.        , -1.5750642 ],\n",
       "       [-0.        , -0.        , -1.59508057],\n",
       "       [-0.        , -0.        , -1.62654631],\n",
       "       [-0.        , -0.        , -1.74299491],\n",
       "       [-0.        , -0.        , -1.58574532],\n",
       "       [-0.        , -0.        , -1.50826021],\n",
       "       [-0.        , -0.        , -1.46767048],\n",
       "       [-0.        , -0.        , -1.7052718 ],\n",
       "       [-0.        , -0.        , -1.6393073 ],\n",
       "       [-0.        , -0.        , -1.56372317],\n",
       "       [-0.        , -0.        , -1.53299035],\n",
       "       [-0.        , -0.        , -1.63386984],\n",
       "       [-0.        , -0.        , -1.64970228],\n",
       "       [-0.        , -0.        , -1.65827165],\n",
       "       [-0.        , -0.        , -1.50722767],\n",
       "       [-0.        , -0.        , -1.65083175],\n",
       "       [-0.        , -0.        , -1.67311795],\n",
       "       [-0.        , -0.        , -1.63565751],\n",
       "       [-0.        , -0.        , -1.53184801],\n",
       "       [-0.        , -0.        , -1.58802982],\n",
       "       [-0.        , -0.        , -1.62257864],\n",
       "       [-0.        , -0.        , -1.52312646]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1, 0, 0] 같은 값들에 확률값들을 곱해줌\n",
    "y_data * np.log(softmax(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.74975921093034"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 값을 최소화 시켜야함\n",
    "-np.sum(np.sum(y_data * np.log(softmax(z)), axis=1).reshape((-1 ,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_data * np.log(softmax(z)), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gradient(y, x, initial_weights, iterations = 500000, alpha=0.001):\n",
    "    cost_history= []\n",
    "    theta_history = []\n",
    "    m = y.shape[0]\n",
    "    theta = np.copy(initial_weights)\n",
    "    \n",
    "    number_of_classes = theta.shape[0]\n",
    "    number_of_weights = theta.shape[1]\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        original_theta = np.copy(theta)\n",
    "        for k in range(number_of_classes):        \n",
    "            for j in range(number_of_weights):\n",
    "                partial_x = x[:, j]\n",
    "                partial_entropy = y - softmax(x.dot(original_theta.T))\n",
    "                theta[k][j]  = original_theta[k][j] + (\n",
    "                    alpha* partial_entropy[:,k].dot(partial_x.T) ) /150\n",
    "        if (_ % 10000) == 0:\n",
    "            print(cross_entropy_function(y,x,theta)/150)\n",
    "            cost_history.append(cross_entropy_function(y,x,theta))\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1515194415967933\n",
      "-0.7467079220794834\n",
      "-0.6122432817217849\n",
      "-0.5385470182850347\n",
      "-0.4903520770729072\n",
      "-0.4553477252611984\n",
      "-0.4281929138432567\n",
      "-0.40617569920236457\n",
      "-0.3877545533048087\n",
      "-0.3719775495409088\n",
      "-0.3582190009206593\n",
      "-0.3460473381710294\n",
      "-0.33515330140936767\n",
      "-0.3253083156481435\n",
      "-0.31633906205234535\n",
      "-0.3081112555346818\n",
      "-0.30051891436978656\n",
      "-0.29347704227820004\n",
      "-0.2869165056926319\n",
      "-0.28078036585544436\n",
      "-0.27502120030395444\n",
      "-0.26959911256194574\n",
      "-0.2644802301516894\n",
      "-0.2596355552701685\n",
      "-0.2550400742167935\n",
      "-0.25067205939275916\n",
      "-0.24651251648334313\n",
      "-0.24254474239486332\n",
      "-0.23875396860162038\n",
      "-0.23512707101838293\n",
      "-0.2316523321703205\n",
      "-0.2283192448298457\n",
      "-0.22511834879721382\n",
      "-0.22204109437160233\n",
      "-0.21907972746762772\n",
      "-0.2162271924023831\n",
      "-0.21347704919834457\n",
      "-0.21082340288120174\n",
      "-0.20826084274500622\n",
      "-0.205784389943737\n",
      "-0.20338945207365366\n",
      "-0.20107178365322245\n",
      "-0.19882745160111945\n",
      "-0.1966528049685095\n",
      "-0.1945444483075841\n",
      "-0.19249921816051332\n",
      "-0.19051416223636986\n",
      "-0.18858652091198536\n",
      "-0.1867137107490395\n",
      "-0.18489330976632518\n"
     ]
    }
   ],
   "source": [
    "theta, cost_history = minimize_gradient(y = y_data, x = x_data_minmax, initial_weights = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56, 119,  17,  39,  42, 137, 129,  51,  40,  16, 108,  57, 126,\n",
       "        37,  79, 147, 102,  17,  80,  26,   9, 141,  32,  40, 133,  20,\n",
       "        18,  25,  85, 140])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, 150, 30)\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.92092254, -1.82443427,  5.01439312, -5.25111263, -4.66639586],\n",
       "       [ 2.85897192,  1.46567666, -1.35681656,  1.33987544, -1.4500308 ],\n",
       "       [-5.4758095 ,  1.82129184, -1.7794219 ,  5.39817948,  7.28623316]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3개의 class가 있고, 5개의 변수가 있었기 때문에 3X5의 matrix\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5860905 ,  2.87228605,  2.51136049],\n",
       "       [-2.80489039,  3.50056779,  3.14604519],\n",
       "       [ 5.90461444,  2.30667061, -5.2100523 ],\n",
       "       [ 5.80111264,  2.44633234, -5.34800821],\n",
       "       [ 5.91600148,  2.2289882 , -5.73685226],\n",
       "       [-2.15551692,  3.08690946,  4.04937972],\n",
       "       [-2.64801921,  3.65811457,  4.19555143],\n",
       "       [-0.4732653 ,  2.98453176,  2.14951232],\n",
       "       [ 6.04429508,  2.24324762, -5.35213831],\n",
       "       [ 6.48287918,  2.11954654, -5.14274982],\n",
       "       [-3.82815711,  3.61638258,  4.92049322],\n",
       "       [ 0.65563999,  2.85567805, -0.63211869],\n",
       "       [-2.05794523,  3.01611678,  3.53016261],\n",
       "       [ 6.60377127,  2.28954601, -5.99256386],\n",
       "       [ 0.49007243,  3.11373543, -0.1926832 ],\n",
       "       [-2.53698929,  2.99519157,  4.50681613],\n",
       "       [-3.65850819,  3.33802133,  5.75441979],\n",
       "       [ 5.90461444,  2.30667061, -5.2100523 ],\n",
       "       [-0.2878751 ,  3.15308831,  0.43249583],\n",
       "       [ 5.37392314,  2.30749295, -4.69991898],\n",
       "       [ 5.47010413,  2.59492588, -5.5303564 ],\n",
       "       [-3.02506874,  2.8975469 ,  5.45432389],\n",
       "       [ 7.4073984 ,  2.15172537, -6.12000787],\n",
       "       [ 6.04429508,  2.24324762, -5.35213831],\n",
       "       [-1.79233021,  3.30621313,  2.9444586 ],\n",
       "       [ 5.47107264,  2.61389157, -5.01324475],\n",
       "       [ 5.96033547,  2.44947725, -4.8544477 ],\n",
       "       [ 4.92705728,  2.65446495, -5.01053476],\n",
       "       [-0.04711745,  2.6481928 ,  2.10245445],\n",
       "       [-3.56315398,  2.86925124,  6.1142069 ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x와 theta_T_j의 linear combination임. 각각의 label별로 z값을 구해줌\n",
    "x_data_minmax[rand_index].dot(theta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.82126785e-02, 5.78532384e-01, 4.03254937e-01],\n",
       "       [1.07219640e-03, 5.87083722e-01, 4.11844082e-01],\n",
       "       [9.73335612e-01, 2.66498926e-02, 1.44951989e-05],\n",
       "       [9.66247591e-01, 3.37385062e-02, 1.39023034e-05],\n",
       "       [9.75557036e-01, 2.44344823e-02, 8.48169376e-06],\n",
       "       [1.45922300e-03, 2.75980575e-01, 7.22560202e-01],\n",
       "       [6.72606103e-04, 3.68535990e-01, 6.30791404e-01],\n",
       "       [2.14957186e-02, 6.82423775e-01, 2.96080507e-01],\n",
       "       [9.78130387e-01, 2.18586237e-02, 1.09897703e-05],\n",
       "       [9.87415579e-01, 1.25755991e-02, 8.82172366e-06],\n",
       "       [1.24786704e-04, 2.13447378e-01, 7.86427835e-01],\n",
       "       [9.70756407e-02, 8.76142312e-01, 2.67820475e-02],\n",
       "       [2.33616634e-03, 3.73371269e-01, 6.24292565e-01],\n",
       "       [9.86796375e-01, 1.32002854e-02, 3.33970962e-06],\n",
       "       [6.53964378e-02, 9.01563786e-01, 3.30397759e-02],\n",
       "       [7.14574737e-04, 1.80569035e-01, 8.18716390e-01],\n",
       "       [7.49652857e-05, 8.19246069e-02, 9.18000428e-01],\n",
       "       [9.73335612e-01, 2.66498926e-02, 1.44951989e-05],\n",
       "       [2.91781561e-02, 9.10855032e-01, 5.99668122e-02],\n",
       "       [9.55448092e-01, 4.45116185e-02, 4.02896088e-05],\n",
       "       [9.46590721e-01, 5.33934761e-02, 1.58023960e-05],\n",
       "       [1.92718632e-04, 7.19586479e-02, 9.27848633e-01],\n",
       "       [9.94807931e-01, 5.19074198e-03, 1.32697072e-06],\n",
       "       [9.78130387e-01, 2.18586237e-02, 1.09897703e-05],\n",
       "       [3.58615128e-03, 5.87351178e-01, 4.09062671e-01],\n",
       "       [9.45663681e-01, 5.43098668e-02, 2.64518177e-05],\n",
       "       [9.70976194e-01, 2.90042893e-02, 1.95167692e-05],\n",
       "       [9.06541853e-01, 9.34143398e-02, 4.38072986e-05],\n",
       "       [4.09982301e-02, 6.07188414e-01, 3.51813356e-01],\n",
       "       [6.03317938e-05, 3.75063093e-02, 9.62433359e-01]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax 함수에 넣어서 확률값을 뱉어내도록 함. 이때 가장 큰 확률값이 우리가 찾고자 하는 label임\n",
    "softmax(x_data_minmax[rand_index].dot(theta.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2,\n",
       "       0, 0, 1, 0, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률값이 가장 큰 것의 index를 뽑아서 y_pred에 저장\n",
    "y_pred = np.argmax(softmax(x_data_minmax[rand_index].dot(theta.T)), axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 1, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2,\n",
       "       0, 0, 2, 0, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(y_data[rand_index], axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 93% 정도 맞는 분류기이다\n",
    "sum(y_pred == y_true) / len(rand_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
