{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwon-yong-geun/miniconda3/envs/ml/lib/python3.8/site-packages/sklearn/datasets/_openml.py:292: UserWarning: Multiple active versions of the dataset matching the name boston exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n",
      "/Users/kwon-yong-geun/miniconda3/envs/ml/lib/python3.8/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "X_data, y_data = datasets.fetch_openml('boston', return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, 0.00000000e+00,\n",
       "        3.14814815e-01, 5.77505269e-01, 6.41606591e-01, 2.69203139e-01,\n",
       "        0.00000000e+00, 2.08015267e-01, 2.87234043e-01, 1.00000000e+00,\n",
       "        8.96799117e-02],\n",
       "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, 0.00000000e+00,\n",
       "        1.72839506e-01, 5.47997701e-01, 7.82698249e-01, 3.48961980e-01,\n",
       "        4.34782609e-02, 1.04961832e-01, 5.53191489e-01, 1.00000000e+00,\n",
       "        2.04470199e-01],\n",
       "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, 0.00000000e+00,\n",
       "        1.72839506e-01, 6.94385898e-01, 5.99382080e-01, 3.48961980e-01,\n",
       "        4.34782609e-02, 1.04961832e-01, 5.53191489e-01, 9.89737254e-01,\n",
       "        6.34657837e-02]])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(X_data)\n",
    "# standard_scale = preprocessing.StandardScaler().fit(X_data)\n",
    "\n",
    "x_scaled_data = minmax_scale.transform(X_data)\n",
    "\n",
    "x_scaled_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled_data, y_data, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-12.96737126   3.83461368   1.5241801    4.52659125  -9.22444293\n",
      "  19.82937951   0.71427628 -14.41565621   7.13852368  -5.33237938\n",
      "  -9.5115654    2.97539012 -20.85980941]\n",
      "intercept:  26.75210351291684\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression(fit_intercept=True,  \n",
    "                                    copy_X=True, # X의 값이 바뀔 수 있기 때문에 X의 값을 복사해놓고 학습하겠다는 의미\n",
    "                                    n_jobs=8) # 몇 개의 cpu를 쓸 것인지\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print('Coefficients: ', regr.coef_)\n",
    "print('intercept: ', regr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_data = np.array(y_data).reshape(506, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>21.549452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>47.464463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>17.218656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>36.586398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>87.288984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x          y\n",
       "0  24  21.549452\n",
       "1  50  47.464463\n",
       "2  15  17.218656\n",
       "3  38  36.586398\n",
       "4  87  87.288984"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"x\"].values.reshape(-1,1)\n",
    "y = df[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(X.size).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((ones, X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD(object):\n",
    "    def __init__(self, fit_intercept=True, copy_X=True,\n",
    "                            eta0=0.001, epochs=1000, weight_decay=0.9):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.copy_X = copy_X\n",
    "        self._eta0 = eta0\n",
    "        self._epochs = epochs\n",
    "\n",
    "        self._cost_history = []\n",
    "\n",
    "        self.theta = None\n",
    "        self._coef = None\n",
    "        self._intercept = None\n",
    "        self._new_X = None\n",
    "        self._w_history = []\n",
    "        self._weight_decay = weight_decay\n",
    "\n",
    "    def cost(self, h, y):\n",
    "        return (1/(2*len(y))) * np.sum((h-y)**2)\n",
    "\n",
    "    def hypothesis_function(self, X, theta):\n",
    "        return X.dot(theta)\n",
    "\n",
    "    def gradient(self, X, y, theta):\n",
    "        m = len(y)\n",
    "        predictions = self.hypothesis_function(X, theta)\n",
    "        gradient = []\n",
    "\n",
    "        for i in range(theta.size):\n",
    "            partial_marginal = X[:, i]\n",
    "            errors_xi = (predictions - y) * partial_marginal\n",
    "            gradient.append((1 / m) * errors_xi.sum())\n",
    "        return np.array(gradient)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._new_X = X\n",
    "        \n",
    "        if self.fit_intercept == True:\n",
    "            ones = np.ones(len(self._new_X)).reshape(-1, 1)\n",
    "            self._new_X = np.concatenate((ones, self._new_X), axis=1)\n",
    "        \n",
    "        theta = np.ones(self._new_X.shape[1])\n",
    "\n",
    "        for epoch in range(self._epochs):\n",
    "\n",
    "            gradient = self.gradient(self._new_X, y, theta).flatten()\n",
    "\n",
    "            for i in range(theta.size):\n",
    "                theta = theta - self._eta0 * gradient\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                self._w_history.append(theta)\n",
    "                cost = self.cost(\n",
    "                    self.hypothesis_function(self._new_X, theta), y)\n",
    "                self._cost_history.append(cost)\n",
    "            self._eta0 = self._eta0 * self._weight_decay\n",
    "\n",
    "        self.theta = theta\n",
    "        self.coef = theta[1:]\n",
    "        self.intercept = theta[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "    # 마지막\n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept == True:\n",
    "            ones = np.ones(len(X)).reshape(-1, 1)\n",
    "            X = np.concatenate((ones, X), axis=1)\n",
    "    \n",
    "        return X.dot(self.theta)\n",
    "\n",
    "    @property\n",
    "    def coef(self):\n",
    "        return self._coef\n",
    "    \n",
    "    @coef.setter\n",
    "    def coef(self, value):\n",
    "        self._coef = value\n",
    "\n",
    "    @property\n",
    "    def intercept(self):\n",
    "        return self._intercept\n",
    "    \n",
    "    @intercept.setter\n",
    "    def intercept(self, value):\n",
    "        self._intercept = value\n",
    "\n",
    "    @property\n",
    "    def weights_history(self):\n",
    "        return np.array(self._w_history)\n",
    "\n",
    "    @property\n",
    "    def cost_history(self):\n",
    "        return self._cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gd = LinearRegressionGD(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegressionGD at 0x7fc70da81d00>"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.32148327, 1.60189569, 1.21371267, 1.53330102, 2.14673479,\n",
       "        2.17976497, 1.54721104, 1.49349507, 1.59756313, 2.06842927,\n",
       "        2.86024511, 1.38825773]),\n",
       " 1.0246018843262803)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gd._coef, lr_gd._intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339,)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gd.predict(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.normal((2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.70182774, 452.85019811])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gd.gradient(X, y, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.983723   0.983723   0.96997259]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegressionGD at 0x7fc70a464730>"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gd.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(n_jobs=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(n_jobs=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(n_jobs=1)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LinearRegression(fit_intercept= True, copy_X=True, n_jobs=1)\n",
    "print(X.shape)\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 1.00077825]), -0.12015553181322502)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.coef_, regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
